// --- SISTEMA ANTITOXIC ---
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const ANTITOXIC_FILE = path.join(__dirname, '../../../database/antitoxic.json');

const CONFIG = {
    COOLDOWN_MS: 30 * 1000, // Cooldown entre avisos para o mesmo usu√°rio
    THRESHOLD: 70, // Score m√≠nimo para considerar t√≥xico (0-100)
    MAX_WARNINGS: 3, // Avisos antes de a√ß√£o autom√°tica
    WARNING_RESET_MS: 24 * 60 * 60 * 1000, // Reset de avisos ap√≥s 24h
    ACTIONS: ['avisar', 'apagar', 'mute'],
    DEFAULT_ACTION: 'avisar'
};

// Palavras-chave para detec√ß√£o r√°pida (fallback se IA falhar)
const TOXIC_KEYWORDS = [
    // Ofensas gerais
    'idiota', 'burro', 'imbecil', 'retardado', 'ot√°rio', 'babaca',
    'est√∫pido', 'cretino', 'mongol', 'd√©bil', 'lixo', 'merda',
    // Termos mais graves (censurados parcialmente)
    'f*der', 'p*ta', 'v*ado', 'c*ralho', 'arr*mbado',
    // Amea√ßas
    'vou te matar', 'vou te pegar', 'vai morrer'
];

// Helper para nome de usu√°rio
const getUserName = (userId) => {
    if (!userId || typeof userId !== 'string') return 'unknown';
    return userId.split('@')[0] || userId;
};

// --- PERSIST√äNCIA ---

const loadAntitoxic = () => {
    try {
        if (fs.existsSync(ANTITOXIC_FILE)) {
            return JSON.parse(fs.readFileSync(ANTITOXIC_FILE, 'utf8'));
        }
    } catch (err) {
        console.error('[ANTITOXIC] Erro ao carregar:', err.message);
    }
    return { groups: {}, userWarnings: {} };
};

const saveAntitoxic = (data) => {
    try {
        const dir = path.dirname(ANTITOXIC_FILE);
        if (!fs.existsSync(dir)) {
            fs.mkdirSync(dir, { recursive: true });
        }
        fs.writeFileSync(ANTITOXIC_FILE, JSON.stringify(data, null, 2));
    } catch (err) {
        console.error('[ANTITOXIC] Erro ao salvar:', err.message);
    }
};

// --- CONFIGURA√á√ÉO DO GRUPO ---

const enableAntitoxic = (groupId, action = CONFIG.DEFAULT_ACTION) => {
    if (!CONFIG.ACTIONS.includes(action)) {
        action = CONFIG.DEFAULT_ACTION;
    }
    
    const data = loadAntitoxic();
    data.groups[groupId] = {
        enabled: true,
        action,
        threshold: CONFIG.THRESHOLD,
        enabledAt: new Date().toISOString(),
        stats: { detected: 0, warned: 0, deleted: 0, muted: 0 }
    };
    saveAntitoxic(data);
    
    return {
        success: true,
        message: `üõ°Ô∏è *ANTITOXIC ATIVADO*\n\n` +
                 `‚ö†Ô∏è *AVISO IMPORTANTE:*\n` +
                 `Este sistema usa IA para detectar mensagens t√≥xicas e *pode cometer erros*. ` +
                 `Nem toda mensagem marcada √© realmente ofensiva, e algumas ofensas podem passar despercebidas.\n\n` +
                 `üìå *Configura√ß√£o:*\n` +
                 `‚Ä¢ A√ß√£o: ${action}\n` +
                 `‚Ä¢ Sensibilidade: ${CONFIG.THRESHOLD}%\n\n` +
                 `üí° Use /antitoxic off para desativar.`
    };
};

const disableAntitoxic = (groupId) => {
    const data = loadAntitoxic();
    if (data.groups[groupId]) {
        data.groups[groupId].enabled = false;
    }
    saveAntitoxic(data);
    
    return {
        success: true,
        message: `üõ°Ô∏è *ANTITOXIC DESATIVADO*\n\n` +
                 `O sistema de detec√ß√£o de toxicidade foi desativado neste grupo.`
    };
};

const setAntitoxicAction = (groupId, action) => {
    if (!CONFIG.ACTIONS.includes(action)) {
        return {
            success: false,
            message: `‚ùå A√ß√£o inv√°lida!\n\nA√ß√µes dispon√≠veis: ${CONFIG.ACTIONS.join(', ')}`
        };
    }
    
    const data = loadAntitoxic();
    if (!data.groups[groupId] || !data.groups[groupId].enabled) {
        return { success: false, message: '‚ùå O antitoxic n√£o est√° ativado neste grupo!' };
    }
    
    data.groups[groupId].action = action;
    saveAntitoxic(data);
    
    return {
        success: true,
        message: `üõ°Ô∏è *ANTITOXIC*\n\nA√ß√£o alterada para: *${action}*`
    };
};

const setAntitoxicThreshold = (groupId, threshold) => {
    const value = parseInt(threshold);
    if (isNaN(value) || value < 1 || value > 100) {
        return { success: false, message: '‚ùå Sensibilidade deve ser entre 1 e 100!' };
    }
    
    const data = loadAntitoxic();
    if (!data.groups[groupId] || !data.groups[groupId].enabled) {
        return { success: false, message: '‚ùå O antitoxic n√£o est√° ativado neste grupo!' };
    }
    
    data.groups[groupId].threshold = value;
    saveAntitoxic(data);
    
    return {
        success: true,
        message: `üõ°Ô∏è *ANTITOXIC*\n\nSensibilidade alterada para: *${value}%*\n\n` +
                 `üí° Quanto maior, menos mensagens ser√£o marcadas.`
    };
};

const getAntitoxicStatus = (groupId) => {
    const data = loadAntitoxic();
    const group = data.groups[groupId];
    
    if (!group || !group.enabled) {
        return {
            success: true,
            enabled: false,
            message: `üõ°Ô∏è *ANTITOXIC*\n\n‚ùå Desativado neste grupo.\n\nüí° Use /antitoxic on para ativar.`
        };
    }
    
    return {
        success: true,
        enabled: true,
        message: `üõ°Ô∏è *ANTITOXIC*\n\n` +
                 `‚úÖ Status: Ativado\n` +
                 `‚ö° A√ß√£o: ${group.action}\n` +
                 `üìä Sensibilidade: ${group.threshold}%\n\n` +
                 `üìà *Estat√≠sticas:*\n` +
                 `‚Ä¢ Detectadas: ${group.stats.detected}\n` +
                 `‚Ä¢ Avisos: ${group.stats.warned}\n` +
                 `‚Ä¢ Apagadas: ${group.stats.deleted}\n` +
                 `‚Ä¢ Mutes: ${group.stats.muted}`
    };
};

// --- DETEC√á√ÉO ---

// Detec√ß√£o r√°pida por palavras-chave (fallback)
const quickCheck = (message) => {
    const lower = message.toLowerCase();
    for (const keyword of TOXIC_KEYWORDS) {
        if (lower.includes(keyword)) {
            return { isToxic: true, score: 80, keyword };
        }
    }
    return { isToxic: false, score: 0 };
};

// Analisar mensagem (para ser chamada com IA)
const analyzeMessage = async (message, aiFunction = null) => {
    // Se n√£o tiver fun√ß√£o de IA, usar detec√ß√£o por palavras-chave
    if (!aiFunction) {
        return quickCheck(message);
    }
    
    try {
        const prompt = `Analise a seguinte mensagem e determine se ela √© t√≥xica, ofensiva ou cont√©m discurso de √≥dio.
Responda APENAS com um JSON no formato: {"score": <0-100>, "reason": "<motivo curto>"}

Onde score √©:
- 0-30: Mensagem normal/aceit√°vel
- 31-60: Levemente inadequada
- 61-80: Ofensiva
- 81-100: Muito t√≥xica/discurso de √≥dio

Mensagem para analisar: "${message.slice(0, 500)}"

Responda apenas o JSON, sem explica√ß√µes adicionais.`;

        const response = await aiFunction(prompt);
        
        // Tentar extrair JSON da resposta
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            const result = JSON.parse(jsonMatch[0]);
            return {
                isToxic: result.score >= CONFIG.THRESHOLD,
                score: result.score,
                reason: result.reason,
                byAI: true
            };
        }
    } catch (err) {
        console.error('[ANTITOXIC] Erro na IA:', err.message);
    }
    
    // Fallback para detec√ß√£o por palavras-chave
    return quickCheck(message);
};

// Processar mensagem (retorna a√ß√£o a ser tomada)
const processMessage = async (groupId, userId, message, aiFunction = null) => {
    const data = loadAntitoxic();
    const group = data.groups[groupId];
    
    // Verificar se est√° ativado
    if (!group || !group.enabled) {
        return { action: 'none' };
    }
    
    // Verificar cooldown
    const userKey = `${groupId}:${odIUserId}`;
    if (data.userWarnings[userKey]) {
        const lastWarning = data.userWarnings[userKey].lastWarning;
        if (Date.now() - lastWarning < CONFIG.COOLDOWN_MS) {
            return { action: 'none', reason: 'cooldown' };
        }
    }
    
    // Analisar mensagem
    const analysis = await analyzeMessage(message, aiFunction);
    
    if (!analysis.isToxic) {
        return { action: 'none' };
    }
    
    // Atualizar estat√≠sticas
    group.stats.detected++;
    
    // Atualizar avisos do usu√°rio
    if (!data.userWarnings[userKey]) {
        data.userWarnings[userKey] = { count: 0, lastWarning: 0 };
    }
    
    const userWarning = data.userWarnings[userKey];
    
    // Reset se passou muito tempo
    if (Date.now() - userWarning.lastWarning > CONFIG.WARNING_RESET_MS) {
        userWarning.count = 0;
    }
    
    userWarning.count++;
    userWarning.lastWarning = Date.now();
    
    // Determinar a√ß√£o
    let action = group.action;
    if (userWarning.count >= CONFIG.MAX_WARNINGS && action === 'avisar') {
        action = 'apagar'; // Escala a√ß√£o ap√≥s m√∫ltiplos avisos
    }
    
    // Atualizar stats
    if (action === 'avisar') group.stats.warned++;
    else if (action === 'apagar') group.stats.deleted++;
    else if (action === 'mute') group.stats.muted++;
    
    saveAntitoxic(data);
    
    return {
        action,
        score: analysis.score,
        reason: analysis.reason || 'Conte√∫do potencialmente ofensivo',
        warningCount: userWarning.count,
        maxWarnings: CONFIG.MAX_WARNINGS,
        byAI: analysis.byAI || false
    };
};

// Gerar mensagem de aviso
const generateWarningMessage = (userId, result) => {
    const aiDisclaimer = result.byAI 
        ? '\n\n_‚ö†Ô∏è Esta an√°lise foi feita por IA e pode conter erros._'
        : '';
    
    if (result.action === 'avisar') {
        return {
            message: `üõ°Ô∏è *ANTITOXIC*\n\n` +
                     `‚ö†Ô∏è @${getUserName(userId)}, sua mensagem foi identificada como potencialmente ofensiva.\n\n` +
                     `üìä Score: ${result.score}/100\n` +
                     `üìå Motivo: ${result.reason}\n` +
                     `‚ö° Avisos: ${result.warningCount}/${result.maxWarnings}` +
                     aiDisclaimer,
            mentions: [userId]
        };
    }
    
    if (result.action === 'apagar') {
        return {
            message: `üõ°Ô∏è *ANTITOXIC*\n\n` +
                     `üóëÔ∏è Mensagem de @${getUserName(userId)} foi removida.\n\n` +
                     `üìå Motivo: ${result.reason}` +
                     aiDisclaimer,
            mentions: [userId]
        };
    }
    
    if (result.action === 'mute') {
        return {
            message: `üõ°Ô∏è *ANTITOXIC*\n\n` +
                     `üîá @${getUserName(userId)} foi silenciado temporariamente.\n\n` +
                     `üìå Motivo: ${result.reason}` +
                     aiDisclaimer,
            mentions: [userId]
        };
    }
    
    return null;
};

// Verificar se grupo tem antitoxic ativado
const isEnabled = (groupId) => {
    const data = loadAntitoxic();
    return data.groups[groupId]?.enabled || false;
};

const getGroupAction = (groupId) => {
    const data = loadAntitoxic();
    return data.groups[groupId]?.action || CONFIG.DEFAULT_ACTION;
};

export {
    enableAntitoxic,
    disableAntitoxic,
    setAntitoxicAction,
    setAntitoxicThreshold,
    getAntitoxicStatus,
    getGroupAction,
    analyzeMessage,
    processMessage,
    generateWarningMessage,
    isEnabled,
    CONFIG as ANTITOXIC_CONFIG
};

export default {
    enableAntitoxic,
    disableAntitoxic,
    setAntitoxicAction,
    setAntitoxicThreshold,
    getAntitoxicStatus,
    getGroupAction,
    analyzeMessage,
    processMessage,
    generateWarningMessage,
    isEnabled
};
